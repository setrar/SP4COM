{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0142bb8-3ab9-4a02-a94c-e216c43ba4eb",
   "metadata": {},
   "source": [
    "# &#x1F4DD; REPORT\n",
    "\n",
    "Brice Setra Robert, June 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf81a44-14dc-4dbe-934f-5777b939ae55",
   "metadata": {},
   "source": [
    "# Homework &#x0033;&#xFE0F;&#x20E3; \n",
    "\n",
    "Homework policy: the homework is individual. Students are encouraged to discuss with fellow students to try to find the main structure of the solution for a problem, especially if they are totally stuck at the beginning of the problem. However, they should work out the details themselves and write down in their own words only what they understand themselves. For every answer you provide, try to give it in its simplest form, while answering correctly. Results that are available in the course notes can be used and referenced and do not need to be rederived.\n",
    "\n",
    "You can answer in French or in English. Do not forget to answer all subquestions. Word processing (Word, Latex,...) would be appreciated, or scanned readable handwritten notes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b39b0f-5f8d-4f6b-bdec-cfcfe136ee89",
   "metadata": {},
   "source": [
    "#### ___Multi-User MISO Downlink___\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f8911f-f785-4df4-b313-5e01f803a6b7",
   "metadata": {},
   "source": [
    "### **&#x2488;** Reduced-Order Zero-Forcing Beamforming and its Average SINR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13a79bb-f571-46b3-a755-709a525d6de5",
   "metadata": {},
   "source": [
    "Consider a MISO Broadcast Channel, i.e. the downlink in a single cell system with a base station (BS) with $N$antennas and $K$ single antenna users. The received signal at user\n",
    "$k$ can be written as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "y_k = \\underbrace{ \\mathbf{h}_k^H \\mathbf{g}_k s_k }_{\\text{signal}}+ \\underbrace{ \\displaystyle\\sum_{i=1,\\neq k}^K \\mathbf{h}_k^H \\mathbf{g}_i s_i}_{\\text{interference}} + \\underbrace{ v_k }_{\\text{noise}}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $s_i$ is the scalar zero mean white signal stream with variance $p_i$ intended for user $i$, which is transmitted with the $N × 1$ beamformer $\\mathbf{g}_i$, and received through the $1 × N$ MISO channel $\\mathbf{h}_k^H$ . The noise $v_k$ is white circularly complex Gaussian with variance $\\sigma_k^2$. All signal and noise terms are independent. Assume the beamformers to be normalized: $\\|\\mathbf{g}_i\\| = 1$. Let the channels be randomly distributed, namely circularly complex Gaussian with i.i.d. entries such that $\\mathbf{h}_k \\sim \\mathcal{CN}(0, \\frac{\\sigma_k}{N} \\mathbf{I}_N )$ where $\\sigma_k = \\mathrm{E}\\|\\mathbf{h}_k\\|^2$ represents the channel attenuation for user $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f5b1d-f36b-408a-9518-020b66b05d72",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x61;)** ___Show that, for given channel $\\mathbf{h}_k$, the Signal to Interference plus Noise Ratio (SINR) in $y_k$ is given by___\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{SINR}_k = \\frac{| \\mathbf{h}_k^H \\mathbf{g}_k |^2 p_k}{ \\sum_{i=1,\\neq k}^K | \\mathbf{h}_k^H \\mathbf{g}_i |^2 p_i + \\sigma_k^2} \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Now, we see in class that optimal beamformers are of the MMSE type, which from the point of view of reception would be making a compromise between interference suppression and matched filtering to avoid noise amplification. To simplify the beamformer design, we shall consider a ”reduced-order” (RO) zero-forcing (ZF) design in which we only ZF to a subset of users. Indeed, considering the interference plus noise denominator in (2), it is important to ZF the interference to users for which the term $| \\mathbf{h}_k^H \\mathbf{g}_i |^2 p_i$ is large compared to $\\sigma_k^2$, and on the contrary, the interference term can be ignored if it is small compared to $\\sigma_k^2$. Let\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "I_k = {i_{k,1},i_{k,2}, \\cdots ,i_{k,K_k}} \\subset I_0 \\backslash \\{k\\} \\text{ , where } I_0 = \\{1,2,...,K\\},\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "be the subset of users that the beamformer $\\mathbf{g}_k$ for user $k$ zero-forces to. Let the size of this subset be $|I_k| = K_k$ where $0 \\leq K_k \\leq K − 1$. The collection of channels of the users being zero forced to appears in the $N × K_k$ matrix\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{H}_{I_k} = [\\mathbf{h}_{i_{k,1}} \\mathbf{h}_{i_{k,2}} \\cdots \\mathbf{h}_{i_{k,K_k}} ].\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In the RO-ZF design, beamformer $\\mathbf{g_k^{ro}}$ must satisfy the constraints\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{H}_{I_k}^H \\mathbf{g}_k^{ro} = 0, \\; \\|\\mathbf{g}_k^{ro}\\| = 1\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "(where the zero is a vector of dimension $K_k × 1$) and this for every $k \\in I_0$.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50917466-52e7-4ddb-87d5-3820f9c54e39",
   "metadata": {},
   "source": [
    "To derive the Signal to Interference plus Noise Ratio (SINR) for user $ k $, we start with the received signal at user $ k $:\n",
    "\n",
    "$ y_k = \\underbrace{ \\mathbf{h}_k^H \\mathbf{g}_k s_k }_{\\text{signal}} + \\underbrace{ \\sum_{i=1, i \\neq k}^K \\mathbf{h}_k^H \\mathbf{g}_i s_i }_{\\text{interference}} + \\underbrace{ v_k }_{\\text{noise}} $\n",
    "\n",
    "where:\n",
    "- $ \\mathbf{h}_k $ is the channel vector for user $ k $\n",
    "- $ \\mathbf{g}_k $ is the beamforming vector for user $ k $\n",
    "- $ s_k $ is the transmitted signal for user $ k $ with variance $ p_k $\n",
    "- $ v_k $ is the noise at user $ k $ with variance $ \\sigma_k^2 $\n",
    "\n",
    "The Signal to Interference plus Noise Ratio (SINR) for user $ k $ is defined as the power of the desired signal divided by the sum of the interference power from other users and the noise power.\n",
    "\n",
    "First, let's identify the power of each component in the received signal $ y_k $:\n",
    "\n",
    "### Signal Power\n",
    "The power of the desired signal is given by the term $ \\mathbf{h}_k^H \\mathbf{g}_k s_k $. The power of this term is:\n",
    "\n",
    "$ \\text{Power of desired signal} = \\left| \\mathbf{h}_k^H \\mathbf{g}_k s_k \\right|^2 $\n",
    "\n",
    "Since $ s_k $ is a zero mean white signal with variance $ p_k $, we have:\n",
    "\n",
    "$ \\text{Power of desired signal} = \\left| \\mathbf{h}_k^H \\mathbf{g}_k \\right|^2 p_k $\n",
    "\n",
    "### Interference Power\n",
    "The interference comes from the signals intended for other users. The interference power is given by:\n",
    "\n",
    "$ \\text{Interference power} = \\sum_{i=1, i \\neq k}^K \\left| \\mathbf{h}_k^H \\mathbf{g}_i s_i \\right|^2 $\n",
    "\n",
    "Each $ s_i $ is a zero mean white signal with variance $ p_i $. Thus, the interference power can be expressed as:\n",
    "\n",
    "$ \\text{Interference power} = \\sum_{i=1, i \\neq k}^K \\left| \\mathbf{h}_k^H \\mathbf{g}_i \\right|^2 p_i $\n",
    "\n",
    "### Noise Power\n",
    "The noise power at user $ k $ is given by the variance of the noise $ v_k $, which is $ \\sigma_k^2 $.\n",
    "\n",
    "### SINR Calculation\n",
    "The SINR for user $ k $ is the ratio of the power of the desired signal to the sum of the interference power and the noise power. Therefore, we can write:\n",
    "\n",
    "$ {\\color{salmon} \\framebox[1][10]{ Solution: } }$ \n",
    "\n",
    "$ \\text{SINR}_k = \\frac{\\text{Power of desired signal}}{\\text{Interference power} + \\text{Noise power}} $\n",
    "\n",
    "Substituting the expressions for the signal, interference, and noise power, we get:\n",
    "\n",
    "$ \\text{SINR}_k = \\frac{\\left| \\mathbf{h}_k^H \\mathbf{g}_k \\right|^2 p_k}{\\sum_{i=1, i \\neq k}^K \\left| \\mathbf{h}_k^H \\mathbf{g}_i \\right|^2 p_i + \\sigma_k^2} $\n",
    "\n",
    "Thus, we have shown that the SINR for user $ k $ is:\n",
    "\n",
    "$ \\boxed { \n",
    "\\text{SINR}_k = \\frac{\\left| \\mathbf{h}_k^H \\mathbf{g}_k \\right|^2 p_k}{\\sum_{i=1, i \\neq k}^K \\left| \\mathbf{h}_k^H \\mathbf{g}_i \\right|^2 p_i + \\sigma_k^2} \n",
    "} $\n",
    "\n",
    "This completes the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c365a8-b8ba-485d-9eb0-e9ce9a10963d",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x62;)** ___By how many complex and by how many real parameters can an unconstrained $N × 1$ complex vector $\\mathbf{g}_k$ be parameterized?___\n",
    "\n",
    "\n",
    "After satisfying the constraints in (5), how many real parameters are left to parameterize $\\mathbf{g}_k^{ro}$?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c7fa40-a42d-4214-880f-788ec262f43c",
   "metadata": {},
   "source": [
    "### Parameterization of an Unconstrained $ N \\times 1 $ Complex Vector $ \\mathbf{g}_k $\n",
    "\n",
    "#### Unconstrained $ N \\times 1 $ Complex Vector\n",
    "\n",
    "An unconstrained $ N \\times 1 $ complex vector $ \\mathbf{g}_k $ has $ N $ complex entries. Each complex entry can be represented by two real numbers (one for the real part and one for the imaginary part).\n",
    "\n",
    "Therefore, the total number of real parameters for an unconstrained $ N \\times 1 $ complex vector is: $ 2N $\n",
    "\n",
    "#### Reduced-Order Zero-Forcing (RO-ZF) Beamforming\n",
    "\n",
    "For the RO-ZF design, the beamforming vector $ \\mathbf{g}_k^{ro} $ must satisfy the following constraints:\n",
    "\n",
    "1. **Zero-Forcing Constraint:** $ \\mathbf{H}_{I_k}^H \\mathbf{g}_k^{ro} = 0 $ where $ \\mathbf{H}_{I_k} $ is an $ N \\times K_k $ matrix composed of the channel vectors of the users that the beamformer $ \\mathbf{g}_k^{ro} $ is zero-forcing to.\n",
    "\n",
    "2. **Normalization Constraint:** $ \\|\\mathbf{g}_k^{ro}\\| = 1 $\n",
    "\n",
    "#### Constraints Analysis\n",
    "\n",
    "1. **Zero-Forcing Constraint:**\n",
    "\n",
    "The zero-forcing constraint $ \\mathbf{H}_{I_k}^H \\mathbf{g}_k^{ro} = 0 $ implies that $ \\mathbf{g}_k^{ro} $ lies in the null space of $ \\mathbf{H}_{I_k}^H $. \n",
    "\n",
    "- $ \\mathbf{H}_{I_k} $ is an $ N \\times K_k $ matrix, so $ \\mathbf{H}_{I_k}^H $ is a $ K_k \\times N $ matrix.\n",
    "- The rank of $ \\mathbf{H}_{I_k}^H $ is at most $ \\min(K_k, N) $. Assuming $ K_k \\leq N $, the rank is $ K_k $.\n",
    "- The dimension of the null space of $ \\mathbf{H}_{I_k}^H $ is $ N - K_k $.\n",
    "\n",
    "Thus, $ \\mathbf{g}_k^{ro} $ must lie in a subspace of dimension $ N - K_k $.\n",
    "\n",
    "2. **Normalization Constraint:**\n",
    "\n",
    "The normalization constraint $ \\|\\mathbf{g}_k^{ro}\\| = 1 $ reduces the degrees of freedom by one.\n",
    "\n",
    "### Total Number of Parameters\n",
    "\n",
    "- The null space of $ \\mathbf{H}_{I_k}^H $ has $ N - K_k $ complex dimensions.\n",
    "- Each complex dimension can be represented by two real numbers.\n",
    "- The normalization constraint reduces the real degrees of freedom by one.\n",
    "\n",
    "Therefore, the total number of real parameters left to parameterize $ \\mathbf{g}_k^{ro} $ is: $ 2(N - K_k) - 1 $\n",
    "\n",
    "$ {\\color{salmon} \\framebox[1][10]{ Solution: } }$ \n",
    "\n",
    "- An unconstrained $ N \\times 1 $ complex vector $ \\mathbf{g}_k $ can be parameterized by $\\boxed{ 2N }$ real parameters.\n",
    "- After satisfying the constraints in (5), the number of real parameters left to parameterize $\\mathbf{g}_k^{ro} $ is: $\\boxed{  2(N - K_k) - 1 }$\n",
    "\n",
    "This reflects the reduction in degrees of freedom due to the zero-forcing and normalization constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd46aa-472b-48e4-baf3-5bb30c5d0247",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x63;)** ___With beamformers of the form $\\mathbf{g}_k^{ro}$, satisfying the constraints (5), how does the SINR expression in (2) change to a slightly modified expression $SINR_k^{ro}$ ?___\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b65008-4720-4cdc-be6d-2ce0c03dc3aa",
   "metadata": {},
   "source": [
    "Given the constraints for the reduced-order zero-forcing (RO-ZF) beamformers $\\mathbf{g}_k^{ro}$, we want to analyze how the SINR expression changes to $ \\text{SINR}_k^{ro} $.\n",
    "\n",
    "The original SINR expression is given by:\n",
    "\n",
    "$ \\text{SINR}_k = \\frac{| \\mathbf{h}_k^H \\mathbf{g}_k |^2 p_k}{ \\sum_{i=1, i \\neq k}^K | \\mathbf{h}_k^H \\mathbf{g}_i |^2 p_i + \\sigma_k^2} $\n",
    "\n",
    "The constraints for the RO-ZF beamformer $\\mathbf{g}_k^{ro}$ are:\n",
    "\n",
    "$ \\mathbf{H}_{I_k}^H \\mathbf{g}_k^{ro} = 0 \\quad \\text{and} \\quad \\|\\mathbf{g}_k^{ro}\\| = 1 $\n",
    "\n",
    "Here, $ I_k = \\{i_{k,1}, i_{k,2}, \\ldots, i_{k,K_k}\\} $ is the subset of users that $\\mathbf{g}_k^{ro}$ zero-forces to.\n",
    "\n",
    "### Modified SINR Expression with RO-ZF Beamformers\n",
    "\n",
    "With the RO-ZF design, the beamformer $\\mathbf{g}_k^{ro}$ zero-forces to a subset of users $ I_k $. Therefore, the interference terms for these users are eliminated. The remaining interference is due to the users outside this subset.\n",
    "\n",
    "The modified SINR expression $ \\text{SINR}_k^{ro} $ can be written as:\n",
    "\n",
    "$ \\text{SINR}_k^{ro} = \\frac{| \\mathbf{h}_k^H \\mathbf{g}_k^{ro} |^2 p_k}{\\sum_{i \\notin \\{k\\} \\cup I_k} | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} |^2 p_i + \\sigma_k^2} $\n",
    "\n",
    "### Explanation\n",
    "\n",
    "1. **Desired Signal Power:**\n",
    "   The desired signal power remains the same as in the original SINR expression since it is the power of the signal intended for user $ k $:\n",
    "\n",
    "   $ \\left| \\mathbf{h}_k^H \\mathbf{g}_k^{ro} \\right|^2 p_k $\n",
    "\n",
    "2. **Interference Power:**\n",
    "   The interference terms corresponding to the users in the subset $ I_k $ are zero because of the zero-forcing constraint. Thus, only the interference from the users outside this subset and not equal to $ k $ contribute to the interference power:\n",
    "\n",
    "   $ \\sum_{i \\notin \\{k\\} \\cup I_k} \\left| \\mathbf{h}_k^H \\mathbf{g}_i^{ro} \\right|^2 p_i $\n",
    "\n",
    "3. **Noise Power:**\n",
    "   The noise power remains unchanged:   $ \\sigma_k^2 $\n",
    "\n",
    "### Final Modified SINR Expression\n",
    "\n",
    "$ {\\color{salmon} \\framebox[1][10]{ Solution: } }$ \n",
    "\n",
    "Therefore, the SINR for user $ k $ with the RO-ZF beamformers is:\n",
    "\n",
    "$\\boxed{\n",
    "\\text{SINR}_k^{ro} = \\frac{| \\mathbf{h}_k^H \\mathbf{g}_k^{ro} |^2 p_k}{\\sum_{i \\notin \\{k\\} \\cup I_k} | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} |^2 p_i + \\sigma_k^2} \n",
    "}$\n",
    "\n",
    "This expression takes into account the fact that the RO-ZF beamformers eliminate interference from a subset of users, thereby reducing the total interference power in the denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7362d952-1fdd-441e-a193-c56d78967685",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In the RO-ZF design, beamformer $\\mathbf{g}_k^{ro}$ prefers to ignore the interference it causes to users in $\\overline{I_k} = I_0 \\backslash I_k$ . Still, to optimize somewhat the resulting $SINR_k^{ro}$, we shall exploit the degrees of design freedom left in $\\mathbf{g}_k^{ro}$ to maximize the signal strength $|\\mathbf{h}^H \\mathbf{g}_k^{ro} |^2$. We shall again do this via the Generalized Sidelobe Canceler (GSC) formulation. For this we shall need the orthogonal projection matrix onto the column space of a tall matrix $\\mathbf{H}$, namely $\\mathbf{P}_{\\mathbf{H}} = \\mathbf{H}(\\mathbf{H}^H\\mathbf{H})^{−1} \\mathbf{H}^H$, and the projection onto its orthogonal complement $\\mathbf{P}_{\\mathbf{H}}^\\perp = \\mathbf{I}_N − \\mathbf{P}_{\\mathbf{H}}$. Remember that any projection matrix satisfies $\\mathbf{P} = \\mathbf{P}^H$ and $\\mathbf{P}^2 = \\mathbf{P}$. We shall also introduce the normalized version of a rectangular matrix $\\mathbf{H}$, namely the semi-unitary $\\overline{\\mathbf{H}} = \\mathbf{H} ( \\mathbf{H}^H \\mathbf{H})^{-H/2} $.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ba6a2-4414-4187-a6d0-cc34fc72a1e7",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x64;)** ___Show that___\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}} = \\mathbf{I}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "which leads to the term ”semi-unitary” for the tall rectangular matrix $\\overline{\\mathbf{H}}$.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72652296-7e96-4767-ad07-e0dc04da16f1",
   "metadata": {},
   "source": [
    "To show that $\\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}} = \\mathbf{I}$ and thus justify the term \"semi-unitary\" for the tall rectangular matrix $\\overline{\\mathbf{H}}$, \n",
    "\n",
    "we start by defining $\\overline{\\mathbf{H}}$ as follows: $\\qquad \\overline{\\mathbf{H}} = \\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-H/2} $ Here, $\\mathbf{H}$ is an $N \\times K$ matrix where $N > K$ (i.e., $\\mathbf{H}$ is a tall matrix).\n",
    "\n",
    "### Step-by-Step Proof\n",
    "\n",
    "1. **Definition of $\\overline{\\mathbf{H}}$:** $\\qquad \\overline{\\mathbf{H}} = \\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-H/2} \\qquad $ This means that $\\overline{\\mathbf{H}}$ is obtained by normalizing $\\mathbf{H}$ with the matrix $(\\mathbf{H}^H \\mathbf{H})^{-H/2}$.\n",
    "\n",
    "2. **Compute $\\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}}$:** $\\qquad \\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}} = \\left(\\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-H/2}\\right)^H \\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-H/2} $\n",
    "\n",
    "3. **Take the Hermitian transpose:** $\\qquad \\left(\\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-H/2}\\right)^H = (\\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-H/2})^H = \\left((\\mathbf{H}^H \\mathbf{H})^{-H/2}\\right)^H \\mathbf{H}^H $\n",
    "\n",
    "Since the Hermitian transpose of a product is the product of the Hermitian transposes in reverse order and $\\mathbf{A}^{H}$ of a matrix $\\mathbf{A}$ is defined as $\\mathbf{A}^H = (\\mathbf{A}^*)^T$:\n",
    "\n",
    "$ \\left((\\mathbf{H}^H \\mathbf{H})^{-H/2}\\right)^H = \\left((\\mathbf{H}^H \\mathbf{H})^{H/2}\\right)^{-1} = \\left((\\mathbf{H}^H \\mathbf{H})^{1/2}\\right)^{-1} = (\\mathbf{H}^H \\mathbf{H})^{-1/2} \\quad$ Thus: $\\quad \\left(\\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-H/2}\\right)^H = (\\mathbf{H}^H \\mathbf{H})^{-1/2} \\mathbf{H}^H $\n",
    "\n",
    "4. **Substitute back:** $\\qquad \\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}} = (\\mathbf{H}^H \\mathbf{H})^{-1/2} \\mathbf{H}^H \\mathbf{H} (\\mathbf{H}^H \\mathbf{H})^{-1/2} $\n",
    "\n",
    "5. **Simplify the expression:** $\\qquad \\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}} = (\\mathbf{H}^H \\mathbf{H})^{-1/2} (\\mathbf{H}^H \\mathbf{H}) (\\mathbf{H}^H \\mathbf{H})^{-1/2} $\n",
    "\n",
    "Since $(\\mathbf{H}^H \\mathbf{H})^{-1/2} (\\mathbf{H}^H \\mathbf{H}) (\\mathbf{H}^H \\mathbf{H})^{-1/2}$ is an identity matrix (by the definition of inverse and properties of the matrix square root): $ \\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}} = \\mathbf{I} $\n",
    "\n",
    "$ {\\color{salmon} \\framebox[1][10]{ Solution: } }$ \n",
    "\n",
    "We have shown that: $\\qquad \\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}} = \\mathbf{I} $\n",
    "\n",
    "This demonstrates that $\\overline{\\mathbf{H}}$ is semi-unitary, meaning that its columns are orthonormal. This property is analogous to a unitary matrix, but since $\\overline{\\mathbf{H}}$ is not square (it is tall and rectangular), we use the term \"semi-unitary.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb288e6-99aa-41f8-b992-2cfd0bbe5523",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x65;)** ___Show the two identities in___\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{P}_H = \\mathbf{P}_{\\overline{H}} = \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^H \n",
    "\\end{equation}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619dd783-3842-402e-89b4-5e5755ce1f5c",
   "metadata": {},
   "source": [
    "To show the two identities in the equation $\\mathbf{P}_H = \\mathbf{P}_{\\overline{H}} = \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^H$, we need to understand the projection matrices $\\mathbf{P}_H$ and $\\mathbf{P}_{\\overline{H}}$, and then show that they are equal to $\\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^H$.\n",
    "\n",
    "### Projection Matrix $\\mathbf{P}_H$\n",
    "\n",
    "The projection matrix onto the column space of a tall matrix $\\mathbf{H}$ is given by: $\\quad \\mathbf{P}_H = \\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-1} \\mathbf{H}^H $\n",
    "\n",
    "### Normalized Version of $\\mathbf{H}$\n",
    "\n",
    "The normalized version of $\\mathbf{H}$ is defined as: $\\quad \\overline{\\mathbf{H}} = \\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-H/2} $\n",
    "\n",
    "### Projection Matrix $\\mathbf{P}_{\\overline{H}}$\n",
    "\n",
    "First, let's compute $\\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^H$: $\\quad \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^H = \\left[\\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-H/2}\\right] \\left[\\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-H/2}\\right]^H $\n",
    "\n",
    "Since $\\overline{\\mathbf{H}}$ is a normalized version of $\\mathbf{H}$, we take the Hermitian transpose: $\\quad \\left[\\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-H/2}\\right]^H = \\left[(\\mathbf{H}^H \\mathbf{H})^{-H/2}\\right]^H \\mathbf{H}^H = (\\mathbf{H}^H \\mathbf{H})^{-1/2} \\mathbf{H}^H $\n",
    "\n",
    "So, $\\quad \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^H = \\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-1/2} (\\mathbf{H}^H \\mathbf{H})^{-1/2} \\mathbf{H}^H $. Simplifying, we get: $\\quad \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^H = \\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-1} \\mathbf{H}^H $\n",
    "\n",
    "### Comparison with $\\mathbf{P}_H$\n",
    "\n",
    "Notice that this is exactly the form of the projection matrix $\\mathbf{P}_H$: $\\quad \\mathbf{P}_H = \\mathbf{H}(\\mathbf{H}^H \\mathbf{H})^{-1} \\mathbf{H}^H $ Thus, we have shown: $\\quad \\mathbf{P}_H = \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^H $\n",
    "\n",
    "Next, since $\\overline{\\mathbf{H}}$ is derived from $\\mathbf{H}$, the projection matrix onto its column space should be the same, hence: $\\quad \\mathbf{P}_{\\overline{H}} = \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^H $\n",
    "\n",
    "$ {\\color{salmon} \\framebox[1][10]{ Solution: } }$ \n",
    "\n",
    "Therefore, we have shown both identities: $\\quad \\boxed{ \\mathbf{P}_H = \\mathbf{P}_{\\overline{H}} = \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^H }$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd5a1b-7b3a-4a9e-b272-11649dce2c3e",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x66;)** ___We introduce similarly the semi-unitary matrix $\\overline{\\mathbf{H}}^\\perp$ of which the columns span the orthogonal complement of the column space of $\\mathbf{H}$. Using the semi-unitarity of both $\\overline{\\mathbf{H}}$ and $\\overline{\\mathbf{H}}^\\perp$ and their mutual orthogonality, show the following three identities___\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "[ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]^H \\, [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ] = \\mathbf{I}_N \\\\\n",
    "[ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ] \\, [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]^H = \\mathbf{I}_N \\\\\n",
    "[ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ] \\, [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]^H =  \\mathbf{P}_{\\overline{H}} +  \\mathbf{P}_{\\overline{H}^\\perp}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "from which you conclude that $\\mathbf{P}_{\\overline{H}^\\perp} =  \\mathbf{P}_{\\overline{H}}^\\perp$.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318715c8-fd58-460b-ad14-09a962fa1ecc",
   "metadata": {},
   "source": [
    "To show the identities and conclude that $\\mathbf{P}_{\\overline{\\mathbf{H}}^\\perp} = \\mathbf{P}_{\\overline{\\mathbf{H}}}^\\perp$, let's analyze the semi-unitary matrices $\\overline{\\mathbf{H}}$ and $\\overline{\\mathbf{H}}^\\perp$.\n",
    "\n",
    "### Identity 1 : $\\quad [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]^H \\, [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ] = \\mathbf{I}_N $\n",
    "\n",
    "Since $\\overline{\\mathbf{H}}$ and $\\overline{\\mathbf{H}}^\\perp$ are semi-unitary and mutually orthogonal, their combined matrix $[ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]$ should be unitary. Let's verify this:\n",
    "\n",
    "1. Take the Hermitian transpose: $\\quad [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]^H = \\begin{bmatrix} \\overline{\\mathbf{H}}^H \\\\ (\\overline{\\mathbf{H}}^\\perp)^H \\end{bmatrix} $\n",
    "\n",
    "2. Multiply with $[ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]$: $\\quad [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]^H \\, [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ] = \\begin{bmatrix} \\overline{\\mathbf{H}}^H \\\\ (\\overline{\\mathbf{H}}^\\perp)^H \\end{bmatrix} \\begin{bmatrix} \\overline{\\mathbf{H}} & \\overline{\\mathbf{H}}^\\perp \\end{bmatrix} $\n",
    "\n",
    "This is a block matrix multiplication: $\\quad = \\begin{bmatrix} \\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}} & \\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}}^\\perp \\\\ (\\overline{\\mathbf{H}}^\\perp)^H \\overline{\\mathbf{H}} & (\\overline{\\mathbf{H}}^\\perp)^H \\overline{\\mathbf{H}}^\\perp \\end{bmatrix} $\n",
    "\n",
    "Since $\\overline{\\mathbf{H}}$ and $\\overline{\\mathbf{H}}^\\perp$ are orthogonal and semi-unitary: \n",
    "$\\quad \\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}} = \\mathbf{I} $\n",
    "$ (\\overline{\\mathbf{H}}^\\perp)^H \\overline{\\mathbf{H}}^\\perp = \\mathbf{I} $\n",
    "$ \\overline{\\mathbf{H}}^H \\overline{\\mathbf{H}}^\\perp = 0 $\n",
    "$ (\\overline{\\mathbf{H}}^\\perp)^H \\overline{\\mathbf{H}} = 0 $\n",
    "\n",
    "Thus, the block matrix becomes: $\\quad = \\begin{bmatrix} \\mathbf{I} & 0 \\\\ 0 & \\mathbf{I} \\end{bmatrix} = \\mathbf{I}_N \\quad$ So, the $\\color{salmon}\\text{first identity is confirmed}$: $\\quad \\boxed{ [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]^H \\, [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ] = \\mathbf{I}_N }$\n",
    "\n",
    "### Identity 2 $\\quad [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ] \\, [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]^H = \\mathbf{I}_N $\n",
    "\n",
    "Since $[ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]$ is a unitary matrix, multiplying it by its Hermitian transpose gives the identity matrix. This follows from the properties of unitary matrices. Hence, the $\\color{salmon} \\text{ second identity holds}$.\n",
    "\n",
    "### Identity 3 $\\quad [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ] \\, [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]^H = \\mathbf{P}_{\\overline{\\mathbf{H}}} + \\mathbf{P}_{\\overline{\\mathbf{H}}^\\perp} $\n",
    "\n",
    "From the first identity, we know that: $\\quad [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ] \\, [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]^H = \\mathbf{I}_N $\n",
    "\n",
    "Since the projection matrices onto the column space of $\\overline{\\mathbf{H}}$ and its orthogonal complement add up to the identity matrix: $\\quad \\mathbf{P}_{\\overline{\\mathbf{H}}} + \\mathbf{P}_{\\overline{\\mathbf{H}}^\\perp} = \\mathbf{I}_N $\n",
    "\n",
    "Therefore, we have: $\\quad \\mathbf{P}_{\\overline{\\mathbf{H}}} + \\mathbf{P}_{\\overline{\\mathbf{H}}^\\perp} = \\mathbf{I}_N \\quad$. So, the $\\color{salmon}\\text{third identity is confirmed}$: $\\quad \\boxed{ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ] \\, [ \\overline{\\mathbf{H}} \\, \\overline{\\mathbf{H}}^\\perp ]^H =  \\mathbf{P}_{\\overline{H}} +  \\mathbf{P}_{\\overline{H}^\\perp} }$\n",
    "\n",
    "$ {\\color{salmon} \\framebox[1][10]{ Solution: } }$ \n",
    "\n",
    "Given that the sum of the projection matrices is the identity matrix, we conclude that: $\\quad \\boxed{ \\mathbf{P}_{\\overline{\\mathbf{H}}^\\perp} = \\mathbf{P}_{\\overline{\\mathbf{H}}}^\\perp }$\n",
    "\n",
    "This demonstrates the orthogonal nature of the projection matrices and confirms the given identities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8670ab14-dace-49a0-959a-4f5d769507c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92630b9e-46a6-4032-b66b-2ad72013894d",
   "metadata": {},
   "source": [
    "In what follows, we shall replace these generic matrices by the specific $\\overline{\\mathbf{H}}_{I_k}$ and $\\overline{\\mathbf{H}}_{I_k}^\\perp$ Consider now a reparameterization of $\\mathbf{g}_k^{ro}$ with $\\mathbf{g}_{k,\\parallel}$, $\\mathbf{g}_{k,\\perp}$ as follows\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{g}_k^{ro} =\n",
    "\\underbrace{[ \\underbrace{\\overline{\\mathbf{H}}_{I_k}}_{N \\times K_k} \\; \\underbrace{\\overline{\\mathbf{H}}_{I_k}^\\perp}_{N \\times (N - K_k)} ] }_{\\text{unitary transformation}}\n",
    " \\Bigg[ \\,\n",
    " \\begin{matrix*}[r]\n",
    "  \\mathbf{g}_{k,\\parallel} \\\\\n",
    "  \\mathbf{g}_{k,\\perp}\n",
    " \\end{matrix*}\n",
    " \\, \\Bigg] .\n",
    " \\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e4f52-992f-454a-8197-f74da52b7d15",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x67;)** ___What are the repercussions of ”forcing the interference to zero” in (5) on $\\mathbf{g}_{k,\\parallel}$ and $\\mathbf{g}_{k,\\perp}$ ? What does the reparameterized $\\mathbf{g}_k^{ro}$ look like after taking this ZF repercussion into account?___\n",
    "\n",
    "The thus reparameterized $\\mathbf{g}_k^{ro}$ represents all possible RO-ZF solutions. We shall optimize the remaining parameters in $\\mathbf{g}_k^{ro}$ by maximizing the received SNR\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{SNR}_k^{ro} = \\frac{| \\mathbf{h}_k^H \\mathbf{g}_k^{ro} |^2 p_k}{\\sigma_k^2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "under the normalization constraint in (5).\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d679920d-1e4f-419a-8209-a24e77b81d92",
   "metadata": {},
   "source": [
    "### Repercussions of \"Forcing the Interference to Zero\" on $\\mathbf{g}_{k,\\parallel}$ and $\\mathbf{g}_{k,\\perp}$\n",
    "\n",
    "Given the reparameterization: $\\quad \\mathbf{g}_k^{ro} = [ \\overline{\\mathbf{H}}_{I_k} \\; \\overline{\\mathbf{H}}_{I_k}^\\perp ] \\begin{bmatrix} \\mathbf{g}_{k,\\parallel} \\\\ \\mathbf{g}_{k,\\perp} \\end{bmatrix} $ where $\\quad \\overline{\\mathbf{H}}_{I_k}$ is $N \\times K_k \\quad$ and $\\quad \\overline{\\mathbf{H}}_{I_k}^\\perp$ is $N \\times (N - K_k), \\quad$ the constraint in (5): $\\quad \\mathbf{H}_{I_k}^H \\mathbf{g}_k^{ro} = 0 $\n",
    "\n",
    "### Analysis of the Zero-Forcing Constraint\n",
    "\n",
    "Using the reparameterization, we have: \n",
    "$\\quad \\mathbf{g}_k^{ro} = \\overline{\\mathbf{H}}_{I_k} \\mathbf{g}_{k,\\parallel} + \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} $\n",
    "\n",
    "The zero-forcing constraint implies:\n",
    "$\\quad \\mathbf{H}_{I_k}^H \\mathbf{g}_k^{ro} = \\mathbf{H}_{I_k}^H (\\overline{\\mathbf{H}}_{I_k} \\mathbf{g}_{k,\\parallel} + \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp}) = 0 $\n",
    "\n",
    "Since $\\overline{\\mathbf{H}}_{I_k}^\\perp$ is orthogonal to $\\overline{\\mathbf{H}}_{I_k}$, the term $\\mathbf{H}_{I_k}^H \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp}$ vanishes. Therefore, we are left with:\n",
    "$\\quad \\mathbf{H}_{I_k}^H \\overline{\\mathbf{H}}_{I_k} \\mathbf{g}_{k,\\parallel} = 0 $\n",
    "\n",
    "Given that $\\overline{\\mathbf{H}}_{I_k}$ is semi-unitary:\n",
    "$\\quad \\mathbf{H}_{I_k}^H \\overline{\\mathbf{H}}_{I_k} = \\mathbf{I}_{K_k} \\quad$\n",
    "Thus, we have:\n",
    "$\\quad \\mathbf{g}_{k,\\parallel} = 0 $\n",
    "\n",
    "### Reparameterized $\\mathbf{g}_k^{ro}$ After ZF Constraint\n",
    "\n",
    "After applying the zero-forcing constraint, the reparameterized beamforming vector $\\mathbf{g}_k^{ro}$ is:\n",
    "$\\quad \\mathbf{g}_k^{ro} = \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} $\n",
    "\n",
    "### Optimizing $\\mathbf{g}_{k,\\perp}$ for Maximum SNR\n",
    "\n",
    "To optimize the remaining parameters in $\\mathbf{g}_k^{ro}$ by maximizing the received SNR, we consider: \n",
    "$\\quad \\text{SNR}_k^{ro} = \\frac{| \\mathbf{h}_k^H \\mathbf{g}_k^{ro} |^2 p_k}{\\sigma_k^2} = \\frac{| \\mathbf{h}_k^H \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} |^2 p_k}{\\sigma_k^2} \\quad$\n",
    "subject to the normalization constraint:\n",
    "$\\quad \\| \\mathbf{g}_k^{ro} \\| = 1 $\n",
    "\n",
    "Since\n",
    "$\\quad \\mathbf{g}_k^{ro} = \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} \\;$, \n",
    "the normalization constraint becomes\n",
    "$\\quad \\| \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} \\| = 1 $\n",
    "\n",
    "Because $\\overline{\\mathbf{H}}_{I_k}^\\perp$ is semi-unitary:\n",
    "$\\quad \\| \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} \\|^2 = (\\mathbf{g}_{k,\\perp})^H (\\overline{\\mathbf{H}}_{I_k}^\\perp)^H \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} = \\| \\mathbf{g}_{k,\\perp} \\|^2 \\quad$\n",
    "Thus:\n",
    "$\\quad \\| \\mathbf{g}_{k,\\perp} \\| = 1 $\n",
    "\n",
    "### Maximizing SNR\n",
    "\n",
    "The SNR can be maximized by choosing $\\mathbf{g}_{k,\\perp}$ to align with the direction that maximizes $| \\mathbf{h}_k^H \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} |$. This can be achieved by setting $\\mathbf{g}_{k,\\perp}$ to the eigenvector corresponding to the largest eigenvalue of the matrix $(\\overline{\\mathbf{H}}_{I_k}^\\perp)^H \\mathbf{h}_k \\mathbf{h}_k^H \\overline{\\mathbf{H}}_{I_k}^\\perp$.\n",
    "\n",
    "$ {\\color{salmon} \\framebox[1][10]{ Solution: } }$ \n",
    "\n",
    "After forcing the interference to zero, $\\mathbf{g}_k^{ro}$ takes the form:\n",
    "$\\; \\boxed{ \\mathbf{g}_k^{ro} = \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} } \\;$\n",
    "where $\\; \\mathbf{g}_{k,\\perp}$ is optimized to maximize the received SNR while satisfying the normalization constraint $\\| \\mathbf{g}_{k,\\perp} \\| = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eea70e-444f-4460-92c7-fb285bb19a96",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x68;)** ___Show that the normalization constraint in (5) now becomes___\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\| \\mathbf{g}_{k,\\perp} \\|^2 = 1\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff8fe53-faf7-4960-88a7-b2301efb31b7",
   "metadata": {},
   "source": [
    "To show that the normalization constraint in (5) becomes $\\| \\mathbf{g}_{k,\\perp} \\|^2 = 1$, we start from the reparameterized form of $\\mathbf{g}_k^{ro}$:\n",
    "$\\quad \\mathbf{g}_k^{ro} = \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} $. \n",
    "\n",
    "The original normalization constraint is:\n",
    "$\\| \\mathbf{g}_k^{ro} \\| = 1 $. This constraint ensures that the beamforming vector $\\mathbf{g}_k^{ro}$ has unit norm. \n",
    "\n",
    "Now, substituting the reparameterized form into this constraint:\n",
    "$\\quad \\| \\mathbf{g}_k^{ro} \\| = \\| \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} \\| = 1 $\n",
    "\n",
    "### Semi-Unitary Property of $\\overline{\\mathbf{H}}_{I_k}^\\perp$\n",
    "\n",
    "Recall that $\\overline{\\mathbf{H}}_{I_k}^\\perp$ is a semi-unitary matrix. This means that its columns are orthonormal, and thus:\n",
    "$\\quad (\\overline{\\mathbf{H}}_{I_k}^\\perp)^H \\overline{\\mathbf{H}}_{I_k}^\\perp = \\mathbf{I}_{N - K_k} $\n",
    "\n",
    "### Norm Calculation\n",
    "\n",
    "Now, we can calculate the norm of $\\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp}$:\n",
    "$\\quad \\| \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} \\|^2 = (\\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp})^H (\\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp}) $\n",
    "\n",
    "Using the property of the semi-unitary matrix:\n",
    "$\\quad = (\\mathbf{g}_{k,\\perp})^H (\\overline{\\mathbf{H}}_{I_k}^\\perp)^H \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} $\n",
    "\n",
    "Since $(\\overline{\\mathbf{H}}_{I_k}^\\perp)^H \\overline{\\mathbf{H}}_{I_k}^\\perp = \\mathbf{I}$, we get:\n",
    "$ = (\\mathbf{g}_{k,\\perp})^H \\mathbf{I} \\mathbf{g}_{k,\\perp} $\n",
    "$ = (\\mathbf{g}_{k,\\perp})^H \\mathbf{g}_{k,\\perp} $\n",
    "$ = \\| \\mathbf{g}_{k,\\perp} \\|^2 $\n",
    "\n",
    "### Final Constraint\n",
    "\n",
    "Therefore, substituting back into the normalization constraint:\n",
    "$\\quad \\| \\mathbf{g}_k^{ro} \\|^2 = \\| \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} \\|^2 = \\| \\mathbf{g}_{k,\\perp} \\|^2 = 1 $\n",
    "\n",
    "This confirms that the normalization constraint for $\\mathbf{g}_{k,\\perp}$ is:\n",
    "$\\quad \\| \\mathbf{g}_{k,\\perp} \\|^2 = 1 $\n",
    "\n",
    "$ {\\color{salmon} \\framebox[1][10]{ Solution: } }$ \n",
    "\n",
    "Thus, we have shown that the normalization constraint for the reparameterized beamforming vector: \n",
    "\n",
    "$\\boxed{  \\quad \\mathbf{g}_k^{ro} \\text{ becomes } \\| \\mathbf{g}_{k,\\perp} \\|^2 = 1 }$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d23cef-3ed3-4df5-92d1-0a14fd40d328",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x69;)** ___Hence, what does the optimization problem (10) under the normalization constraint (11) become for the remaining parameters in $\\mathbf{g}_k^{ro}$? In other words, what are the free parameters, parameterizing which remaining cost function, under which constraint?___\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368674da-f3e1-4b3a-89f0-02493fda96ee",
   "metadata": {},
   "source": [
    "To frame the optimization problem for $\\mathbf{g}_k^{ro}$ under the normalization constraint, we start from the given SNR expression:\n",
    "$ \\text{SNR}_k^{ro} = \\frac{| \\mathbf{h}_k^H \\mathbf{g}_k^{ro} |^2 p_k}{\\sigma_k^2} $\n",
    "and the normalization constraint:\n",
    "$ \\| \\mathbf{g}_{k,\\perp} \\|^2 = 1 $\n",
    "\n",
    "### Reparameterized Beamforming Vector\n",
    "\n",
    "From the reparameterization, we have:\n",
    "$\\quad \\mathbf{g}_k^{ro} = \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} $\n",
    "\n",
    "### Substitution into the SNR Expression\n",
    "\n",
    "Substituting $\\mathbf{g}_k^{ro} = \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp}$ into the SNR expression:\n",
    "$\\quad \\text{SNR}_k^{ro} = \\frac{| \\mathbf{h}_k^H \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} |^2 p_k}{\\sigma_k^2} $\n",
    "\n",
    "### Optimization Problem\n",
    "\n",
    "We aim to maximize the SNR by optimizing $\\mathbf{g}_{k,\\perp}$ under the constraint that $\\| \\mathbf{g}_{k,\\perp} \\|^2 = 1$.\n",
    "\n",
    "#### Objective Function\n",
    "\n",
    "The objective function to maximize is:\n",
    "$\\; | \\mathbf{h}_k^H \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} |^2 \\;$\n",
    "since $ p_k $ and $\\sigma_k^2$ are constants.\n",
    "\n",
    "#### Constraint\n",
    "\n",
    "The constraint is:\n",
    "$\\; \\| \\mathbf{g}_{k,\\perp} \\|^2 = 1 $\n",
    "\n",
    "### Reformulated Optimization Problem\n",
    "\n",
    "The optimization problem can be written as: $ \\max_{\\mathbf{g}_{k,\\perp}} \\; | \\mathbf{h}_k^H \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} |^2 $ subject to: $ \\| \\mathbf{g}_{k,\\perp} \\|^2 = 1 $\n",
    "\n",
    "### Free Parameters and Cost Function\n",
    "\n",
    "The free parameters are the entries of $\\mathbf{g}_{k,\\perp}$, which is an $(N - K_k) \\times 1$ vector. The remaining $\\color{salmon} \\text{cost function}$ to maximize is $ | \\mathbf{h}_k^H \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} |^2 $, under the unit-norm constraint for $\\mathbf{g}_{k,\\perp}$.\n",
    "\n",
    "$ {\\color{salmon} \\framebox[1][10]{ Solution: } }$ of the Optimization Problem\n",
    "\n",
    "- **Objective Function**: Maximize $ | \\mathbf{h}_k^H \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} |^2 $\n",
    "- **Free Parameters**: The components of the vector $\\mathbf{g}_{k,\\perp}$\n",
    "- **Constraint**: $ \\| \\mathbf{g}_{k,\\perp} \\|^2 = 1 $\n",
    "\n",
    "This is a classic problem of maximizing the quadratic form under a quadratic constraint, typically solved by finding the dominant eigenvector of the matrix $ (\\overline{\\mathbf{H}}_{I_k}^\\perp)^H \\mathbf{h}_k \\mathbf{h}_k^H \\overline{\\mathbf{H}}_{I_k}^\\perp $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0956c-3934-4a47-b0bd-58ed313af44d",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x6a;)** ___Show that the resulting solution for the free parameters, when substituted in (9), leads to___\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{g}_k^{ro} = \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k / \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\|\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "which is the reduced-order MMSE-ZF beamformer.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a51f28d-aa8d-4f28-b270-ac0b23fc99e3",
   "metadata": {},
   "source": [
    "To show that the resulting solution for the free parameters leads to:\n",
    "$\\; \\mathbf{g}_k^{ro} = \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k / \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\| $ we start with the reparameterization of $\\mathbf{g}_k^{ro}$ and the optimization problem.\n",
    "\n",
    "### Reparameterization of $\\mathbf{g}_k^{ro}$\n",
    "\n",
    "The beamforming vector $\\mathbf{g}_k^{ro}$ is reparameterized as:\n",
    "$\\; \\mathbf{g}_k^{ro} = [ \\overline{\\mathbf{H}}_{I_k} \\; \\overline{\\mathbf{H}}_{I_k}^\\perp ] \\begin{bmatrix} \\mathbf{g}_{k,\\parallel} \\\\ \\mathbf{g}_{k,\\perp} \\end{bmatrix} $\n",
    "\n",
    "### Zero-Forcing Constraint\n",
    "\n",
    "From the zero-forcing constraint $\\mathbf{H}_{I_k}^H \\mathbf{g}_k^{ro} = 0$, we have:\n",
    "$\\; \\mathbf{g}_{k,\\parallel} = 0 $\n",
    "This simplifies $\\mathbf{g}_k^{ro}$ to:\n",
    "$\\; \\mathbf{g}_k^{ro} = \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} $\n",
    "\n",
    "### Optimization Problem\n",
    "\n",
    "The optimization problem to maximize the SNR is:\n",
    "$\\; \\max_{\\mathbf{g}_{k,\\perp}} \\; | \\mathbf{h}_k^H \\overline{\\mathbf{H}}_{I_k}^\\perp \\mathbf{g}_{k,\\perp} |^2 $\n",
    "subject to the constraint:\n",
    "$\\; \\| \\mathbf{g}_{k,\\perp} \\|^2 = 1 $\n",
    "\n",
    "### Solution Using Projections\n",
    "\n",
    "The optimal solution for $\\mathbf{g}_{k,\\perp}$ aligns it in the direction that maximizes the projection of $\\mathbf{h}_k$ onto the subspace spanned by $\\overline{\\mathbf{H}}_{I_k}^\\perp$. This can be achieved by choosing $\\mathbf{g}_{k,\\perp}$ to be the normalized projection of $\\mathbf{h}_k$ onto the orthogonal complement of the column space of $\\mathbf{H}_{I_k}$.\n",
    "\n",
    "The projection matrix onto the orthogonal complement of the column space of $\\mathbf{H}_{I_k}$ is given by:\n",
    "$\\; \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp = \\mathbf{I} - \\mathbf{P}_{\\mathbf{H}_{I_k}} $\n",
    "where $\\mathbf{P}_{\\mathbf{H}_{I_k}}$ is the projection matrix onto the column space of $\\mathbf{H}_{I_k}$:\n",
    "$\\; \\mathbf{P}_{\\mathbf{H}_{I_k}} = \\mathbf{H}_{I_k} (\\mathbf{H}_{I_k}^H \\mathbf{H}_{I_k})^{-1} \\mathbf{H}_{I_k}^H $\n",
    "\n",
    "Therefore, the orthogonal projection is:\n",
    "$\\; \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k = \\left( \\mathbf{I} - \\mathbf{H}_{I_k} (\\mathbf{H}_{I_k}^H \\mathbf{H}_{I_k})^{-1} \\mathbf{H}_{I_k}^H \\right) \\mathbf{h}_k $\n",
    "\n",
    "### Normalizing the Beamforming Vector\n",
    "\n",
    "The beamforming vector $\\mathbf{g}_k^{ro}$ is then given by normalizing this projection:\n",
    "$\\; \\mathbf{g}_k^{ro} = \\frac{\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k}{\\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\|} $\n",
    "\n",
    "$ {\\color{salmon} \\framebox[1][10]{ Solution: } }$\n",
    "\n",
    "Thus, we have shown that the resulting solution for the free parameters, when substituted into the reparameterized form $\\mathbf{g}_k^{ro}$, leads to the $\\color{teal} \\text{ reduced-order MMSE-ZF}$ beamformer:\n",
    "$\\; \\boxed{ \\mathbf{g}_k^{ro} = \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k / \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\| }$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f175dd12-903f-4a2b-bec0-94909dd5362e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In the massive MIMO regime, as $N \\to \\infty$, the scalar signal and interference powers appearing\n",
    "in $\\text{SINR}_k^{ro}$ under `(c)` converge to their expected value as a function of the random channels, due to the law of large numbers. I.e. we can write\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{SINR}_k^{ro} = \\frac{P_{S,k}}{P_{I,k} + \\sigma_k^2} .\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51323b61-562a-40d8-9208-cb58869ffaf6",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x6b;)** ___Show that___\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_k^H \\, \\mathbf{g}_k^{ro} = \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\|  .\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef7269c-3f66-447a-921c-4dab0ae36ccb",
   "metadata": {},
   "source": [
    "To show that $ \\mathbf{h}_k^H \\, \\mathbf{g}_k^{ro} = \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\| $ we start with the expression for $\\mathbf{g}_k^{ro}$ in the reduced-order zero-forcing (RO-ZF) beamformer:\n",
    "$\\; \\mathbf{g}_k^{ro} = \\frac{\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k}{\\|\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k\\|} $ where $\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp$ is the orthogonal projection matrix onto the orthogonal complement of the column space of $\\mathbf{H}_{I_k}$.\n",
    "\n",
    "### Step-by-Step Proof\n",
    "\n",
    "1. **Projection Matrix Definition:**\n",
    "\n",
    "   The projection matrix onto the orthogonal complement of $\\mathbf{H}_{I_k}$ is given by: $ \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp = \\mathbf{I} - \\mathbf{P}_{\\mathbf{H}_{I_k}} $ where $\\mathbf{P}_{\\mathbf{H}_{I_k}}$ is the projection matrix onto the column space of $\\mathbf{H}_{I_k}$ : $\\; \\mathbf{P}_{\\mathbf{H}_{I_k}} = \\mathbf{H}_{I_k} (\\mathbf{H}_{I_k}^H \\mathbf{H}_{I_k})^{-1} \\mathbf{H}_{I_k}^H $\n",
    "\n",
    "2. **Substitute $\\mathbf{g}_k^{ro}$:**\n",
    "\n",
    "   Substitute $\\mathbf{g}_k^{ro}$ into $\\mathbf{h}_k^H \\mathbf{g}_k^{ro}$: $\\; \\mathbf{h}_k^H \\mathbf{g}_k^{ro} = \\mathbf{h}_k^H \\frac{\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k}{\\|\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k\\|} $\n",
    "\n",
    "3. **Simplify the Expression:**\n",
    "\n",
    "   Note that $\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k$ is the projection of $\\mathbf{h}_k$ onto the orthogonal complement of the column space of $\\mathbf{H}_{I_k}$. Thus, the term $\\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k$ is the inner product of $\\mathbf{h}_k$ with its projection onto this orthogonal complement.\n",
    "\n",
    "   By properties of projection matrices: $ \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp = (\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k)^H $ Therefore: $ \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k = (\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k)^H \\mathbf{h}_k = \\|\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k\\|^2 $\n",
    "\n",
    "4. **Normalization:**\n",
    "\n",
    "   Since $\\mathbf{g}_k^{ro} = \\frac{\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k}{\\|\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k\\|}$, we get: $ \\mathbf{h}_k^H \\mathbf{g}_k^{ro} = \\frac{\\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k}{\\|\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k\\|} $ Simplifying this, we obtain: $ \\mathbf{h}_k^H \\mathbf{g}_k^{ro} = \\frac{\\|\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k\\|^2}{\\|\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k\\|} $\n",
    "\n",
    "5. **$ {\\color{salmon} \\framebox[1][10]{ Solution: } }$**\n",
    "\n",
    "   Therefore, the expression simplifies to: $\\boxed{ \\mathbf{h}_k^H \\mathbf{g}_k^{ro} = \\|\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k\\| }$ This confirms the desired result: $ \\mathbf{h}_k^H \\mathbf{g}_k^{ro} = \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\| $\n",
    "\n",
    "This shows that the inner product of $\\mathbf{h}_k$ with its beamforming vector $\\mathbf{g}_k^{ro}$ is equal to the norm of the projection of $\\mathbf{h}_k$ onto the orthogonal complement of the column space of $\\mathbf{H}_{I_k}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4935b3-ca8f-41c8-9950-cb31da8570d6",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x6c;)** ___Hence show that___\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "P_{S,k}/p_k = \\mathrm{E} \\| \\mathbf{h}_k^H \\, \\mathbf{g}_k^{ro} \\|^2 = \\mathrm{E}_{\\mathbf{H}_{I_k}} \\mathrm{E}_{\\mathbf{h}_k} \\mathrm{tr}\\{ \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\}  .\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2100911b-e94c-4c65-8e98-8e2cbff760c7",
   "metadata": {},
   "source": [
    "To show that $ \\frac{P_{S,k}}{p_k} = \\mathrm{E} \\left[ \\| \\mathbf{h}_k^H \\, \\mathbf{g}_k^{ro} \\|^2 \\right] = \\mathrm{E}_{\\mathbf{H}_{I_k}} \\left[ \\mathrm{E}_{\\mathbf{h}_k} \\left[ \\mathrm{tr}\\left\\{ \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\right\\} \\right] \\right] $ we need to relate the expected value of the signal power to the projection matrix $\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp$ and use the results from parts `(c)` and `(j)`.\n",
    "\n",
    "### Signal Power and Its Expectation\n",
    "\n",
    "From part `(j)`, we have: $ \\mathbf{h}_k^H \\mathbf{g}_k^{ro} = \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\| $ Thus, the signal power can be written as: $ P_{S,k} = p_k \\| \\mathbf{h}_k^H \\mathbf{g}_k^{ro} \\|^2 $\n",
    "\n",
    "Given that: $ \\mathbf{h}_k^H \\mathbf{g}_k^{ro} = \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\| $ we have: $ \\| \\mathbf{h}_k^H \\mathbf{g}_k^{ro} \\|^2 = \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\|^2 $ Therefore: $ P_{S,k} = p_k \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\|^2 $\n",
    "\n",
    "### Expected Signal Power\n",
    "\n",
    "We need to find the expected value of the signal power over the random channels. This can be written as: $ \\mathrm{E} \\left[ \\| \\mathbf{h}_k^H \\, \\mathbf{g}_k^{ro} \\|^2 \\right] = \\mathrm{E} \\left[ \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\|^2 \\right] $ Using the properties of the projection matrix, we know that: $ \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\|^2 = \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k $ Therefore: $ \\mathrm{E} \\left[ \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\|^2 \\right] = \\mathrm{E} \\left[ \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\right] $\n",
    "\n",
    "### Trace and Expectation\n",
    "\n",
    "Now, using the trace operator, we can write: $ \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k = \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\right) $ Therefore: $ \\mathrm{E} \\left[ \\| \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\|^2 \\right] = \\mathrm{E} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\right) \\right] $ Since $\\mathbf{h}_k$ and $\\mathbf{H}_{I_k}$ are independent random variables, we can take the expectation separately: $ \\mathrm{E} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\right) \\right] = \\mathrm{E}_{\\mathbf{H}_{I_k}} \\left[ \\mathrm{E}_{\\mathbf{h}_k} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\right) \\right] \\right] $\n",
    "\n",
    "#### $ {\\color{salmon} \\framebox[1][10]{ Solution: } }$\n",
    "\n",
    "Combining these results, we have: $\\boxed{  \\frac{P_{S,k}}{p_k} = \\mathrm{E} \\left[ \\| \\mathbf{h}_k^H \\, \\mathbf{g}_k^{ro} \\|^2 \\right] = \\mathrm{E}_{\\mathbf{H}_{I_k}} \\left[ \\mathrm{E}_{\\mathbf{h}_k} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\right) \\right] \\right] }$ This completes the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f6fce-7588-4f02-9d5e-40e6077e1538",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x6d;)** ___Continue this result to show that___\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "P_{S,k}/p_k &= \\frac{\\sigma_k}{N}\\mathrm{E}_{\\mathbf{H}_{I_k}} \\mathrm{tr}\\{ \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\} = \\frac{\\sigma_k}{N}\\mathrm{E}_{\\mathbf{H}_{I_k}} \\mathrm{tr}\\{ \\overline{\\mathbf{H}}_{I_k}^\\perp \\, \\overline{\\mathbf{H}}_{I_k}^{\\perp H } \\} = \\frac{\\sigma_k}{N}\\mathrm{E}_{\\mathbf{H}_{I_k}} \\mathrm{tr}\\{ \\overline{\\mathbf{H}}_{I_k}^{\\perp H } \\, \\overline{\\mathbf{H}}_{I_k}^\\perp \\} \\\\\n",
    "&= \\frac{\\sigma_k}{N}\\mathrm{E}_{\\mathbf{H}_{I_k}} \\mathrm{tr}\\{ \\mathbf{I}_{N - K_k} \\} = \\frac{\\sigma_k}{N} \\mathrm{tr}\\{ \\mathbf{I}_{N - K_k} \\} = \\sigma_k ( 1 - \\frac{K_k}{N})\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which shows how the signal power decreases with increasing ZF order $K_k$.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104a5ae-07f1-4f91-918a-77a368bd0434",
   "metadata": {},
   "source": [
    "To continue from the previous result and show that $ \\frac{P_{S,k}}{p_k} = \\frac{\\sigma_k}{N}\\mathrm{E}_{\\mathbf{H}_{I_k}} \\mathrm{tr}\\{ \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\} = \\sigma_k \\left( 1 - \\frac{K_k}{N} \\right), $ we proceed step-by-step.\n",
    "\n",
    "### Expected Signal Power $ P_{S,k} / p_k $\n",
    "\n",
    "We previously derived: $ \\frac{P_{S,k}}{p_k} = \\mathrm{E} \\left[ \\| \\mathbf{h}_k^H \\mathbf{g}_k^{ro} \\|^2 \\right] = \\mathrm{E}_{\\mathbf{H}_{I_k}} \\left[ \\mathrm{E}_{\\mathbf{h}_k} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\right) \\right] \\right] $\n",
    "\n",
    "Given that $\\mathbf{h}_k \\sim \\mathcal{CN}(0, \\frac{\\sigma_k}{N} \\mathbf{I}_N)$, we can use the properties of the trace operator and expectation to simplify this expression.\n",
    "\n",
    "### Expectation of $\\mathbf{h}_k \\mathbf{h}_k^H$\n",
    "\n",
    "Since $\\mathbf{h}_k \\sim \\mathcal{CN}(0, \\frac{\\sigma_k}{N} \\mathbf{I}_N)$, the covariance matrix of $\\mathbf{h}_k$ is $\\frac{\\sigma_k}{N} \\mathbf{I}_N$. Therefore, the expected value of the outer product $\\mathbf{h}_k \\mathbf{h}_k^H$ is: $ \\mathrm{E}_{\\mathbf{h}_k} [\\mathbf{h}_k \\mathbf{h}_k^H] = \\frac{\\sigma_k}{N} \\mathbf{I}_N $\n",
    "\n",
    "### Substitution into the Trace Expression\n",
    "\n",
    "Substitute this into the expected trace expression: $ \\mathrm{E}_{\\mathbf{h}_k} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\right) \\right] = \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathrm{E}_{\\mathbf{h}_k} \\left[ \\mathbf{h}_k \\mathbf{h}_k^H \\right] \\right) = \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\frac{\\sigma_k}{N} \\mathbf{I}_N \\right) $\n",
    "\n",
    "### Simplifying the Trace\n",
    "\n",
    "Since $\\frac{\\sigma_k}{N} \\mathbf{I}_N$ is a scalar multiple of the identity matrix, we can pull out the scalar $\\frac{\\sigma_k}{N}$: $ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\frac{\\sigma_k}{N} \\mathbf{I}_N \\right) = \\frac{\\sigma_k}{N} \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\mathbf{I}_N \\right) = \\frac{\\sigma_k}{N} \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\right) $\n",
    "\n",
    "### Expected Value over $\\mathbf{H}_{I_k}$\n",
    "\n",
    "Thus, we have: $ \\frac{P_{S,k}}{p_k} = \\frac{\\sigma_k}{N} \\mathrm{E}_{\\mathbf{H}_{I_k}} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\right) \\right] $\n",
    "\n",
    "### Properties of the Projection Matrix\n",
    "\n",
    "Recall that $\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp = \\mathbf{I} - \\mathbf{P}_{\\mathbf{H}_{I_k}}$, where $\\mathbf{P}_{\\mathbf{H}_{I_k}} = \\mathbf{H}_{I_k} (\\mathbf{H}_{I_k}^H \\mathbf{H}_{I_k})^{-1} \\mathbf{H}_{I_k}^H$. The rank of $\\mathbf{P}_{\\mathbf{H}_{I_k}}$ is $K_k$, which is the number of users being zero-forced.\n",
    "\n",
    "Therefore, the rank of $\\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp$ is $N - K_k$. The trace of a projection matrix is equal to its rank, so: $ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\right) = N - K_k $\n",
    "\n",
    "#### $ {\\color{salmon} \\framebox[1][10]{ Solution: } }$\n",
    "\n",
    "Putting it all together: $ \\frac{P_{S,k}}{p_k} = \\frac{\\sigma_k}{N} \\mathrm{E}_{\\mathbf{H}_{I_k}} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_k}}^\\perp \\right) \\right] = \\frac{\\sigma_k}{N} (N - K_k) $ Thus, we get: $\\boxed{ \\frac{P_{S,k}}{p_k} = \\sigma_k \\left( 1 - \\frac{K_k}{N} \\right) }$ This shows how the signal power decreases with increasing ZF order $K_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e036360-46f5-45d4-99ad-55e81e658bf3",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x6e;)** ___In the computation of the interference power $P_{I,k} \\,$, show that___\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "| \\mathbf{h}_k^H \\, \\mathbf{g}_k^{ro} |^2 = \\frac{| \\mathbf{h}_k^H \\, \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2}{\\| \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i \\|^2} , \\text{ hence } \\, \\mathrm{E} | \\mathbf{h}_k^H \\, \\mathbf{g}_k^{ro} |^2 = \\frac{\\mathrm{E} | \\mathbf{h}_k^H \\, \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2}{P_{S,i}/p_i}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where we assume that we are in a regime of a large number of antennas so that the\n",
    "expectation of the ratio considered becomes the ratio of the expectations.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c82873-742b-48f0-86eb-b9871f0feb4f",
   "metadata": {},
   "source": [
    "To show the given expression for the interference power $ P_{I,k} $: $ | \\mathbf{h}_k^H \\, \\mathbf{g}_i^{ro} |^2 = \\frac{| \\mathbf{h}_k^H \\, \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2}{\\| \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i \\|^2} $ and $ \\mathrm{E} | \\mathbf{h}_k^H \\, \\mathbf{g}_i^{ro} |^2 = \\frac{\\mathrm{E} | \\mathbf{h}_k^H \\, \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2}{P_{S,i}/p_i}, $ we need to analyze the beamforming vectors and the interference terms.\n",
    "\n",
    "### Interference Power Calculation\n",
    "\n",
    "1. **Beamforming Vector $\\mathbf{g}_i^{ro}$**:\n",
    "\n",
    "   For user $ i $, the beamforming vector in the reduced-order zero-forcing (RO-ZF) design is given by: $ \\mathbf{g}_i^{ro} = \\frac{\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i}{\\|\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i\\|} $\n",
    "   - Here, $\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp$ is the orthogonal projection matrix onto the orthogonal complement of the column space of $\\mathbf{H}_{I_i}$.\n",
    "\n",
    "3. **Interference Term $|\\mathbf{h}_k^H \\mathbf{g}_i^{ro}|$**:\n",
    "\n",
    "   The interference power from user $ i $ at user $ k $ is given by $|\\mathbf{h}_k^H \\mathbf{g}_i^{ro}|$.\n",
    "   - Substitute $\\mathbf{g}_i^{ro}$ into this expression: $ | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} | = \\left| \\mathbf{h}_k^H \\frac{\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i}{\\|\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i\\|} \\right| $\n",
    "   - Simplify this expression: $ | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} | = \\frac{|\\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i|}{\\|\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i\\|} $ by squaring both sides to get the power term: $ | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} |^2 = \\frac{|\\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i|^2}{\\|\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i\\|^2} $\n",
    "\n",
    "### Expected Value of the Interference Term\n",
    "\n",
    "3. **Expectation of the Interference Power**:\n",
    "\n",
    "   We need to compute the expected value of the interference term $|\\mathbf{h}_k^H \\mathbf{g}_i^{ro} |^2$: $ \\mathrm{E} \\left[ | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} |^2 \\right] = \\mathrm{E} \\left[ \\frac{|\\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i|^2}{\\|\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i\\|^2} \\right] $. Assuming a large number of antennas so that the expectation of the ratio becomes the ratio of the expectations: $ \\mathrm{E} \\left[ \\frac{|\\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i|^2}{\\|\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i\\|^2} \\right] \\approx \\frac{\\mathrm{E} \\left[ |\\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i|^2 \\right]}{\\mathrm{E} \\left[ \\|\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i\\|^2 \\right]} $\n",
    "\n",
    "5. **Denominator Simplification**:\n",
    "\n",
    "   From part **&#x1F516;** **(&#x6c;)** , we know that: $ \\mathrm{E} \\left[ \\|\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i\\|^2 \\right] = P_{S,i}/p_i $. So, we have: $ \\mathrm{E} \\left[ | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} |^2 \\right] = \\frac{\\mathrm{E} \\left[ |\\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i|^2 \\right]}{P_{S,i}/p_i} $\n",
    "\n",
    "#### $ {\\color{salmon} \\framebox[1][10]{ Solution: } }$\n",
    "\n",
    "Therefore, we have shown that: $\\boxed{ | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} |^2 = \\frac{|\\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i|^2}{\\|\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i\\|^2} \\text{ and } \\mathrm{E} \\left[ | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} |^2 \\right] = \\frac{\\mathrm{E} \\left[ |\\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i|^2 \\right]}{P_{S,i}/p_i} }$ as required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc50555-cc30-4f41-b168-714df84323f3",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x6f;)** ___Next, show that for $k \\notin I_i$___,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{E} | \\mathbf{h}_k^H \\, \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2 = \n",
    "\\mathrm{E}\\Big( \\mathrm{tr}\\{ \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i \\mathbf{h}_i^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\} \\Big) = \\frac{\\alpha_k \\alpha_i}{N^2} \\mathrm{tr}\\{ \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\} = \\frac{\\alpha_k \\alpha_i}{N} (1 - \\frac{K_i}{N}) .\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499b7ceb-0204-4557-b956-6eb298573c4d",
   "metadata": {},
   "source": [
    "To show the given result for $ k \\notin I_i $: $ \\mathrm{E} | \\mathbf{h}_k^H \\, \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2 = \\mathrm{E}\\left( \\mathrm{tr}\\{ \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i \\mathbf{h}_i^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\} \\right) = \\frac{\\alpha_k \\alpha_i}{N^2} \\mathrm{tr}\\{ \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\} = \\frac{\\alpha_k \\alpha_i}{N} \\left(1 - \\frac{K_i}{N}\\right) $. We will go through the steps one by one.\n",
    "\n",
    "### Interference Term\n",
    "\n",
    "First, consider the term $\\mathrm{E} | \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2$: $ \\mathrm{E} | \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2 $. Since $\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp$ is a projection matrix and $\\mathbf{h}_i, \\mathbf{h}_k \\sim \\mathcal{CN}(0, \\frac{\\alpha_i}{N} \\mathbf{I}_N), \\mathcal{CN}(0, \\frac{\\alpha_k}{N} \\mathbf{I}_N)$ respectively, we proceed as follows:\n",
    "\n",
    "### Expected Value\n",
    "\n",
    "Using the properties of the trace operator and the independence of $\\mathbf{h}_i$ and $\\mathbf{h}_k$: $ \\mathrm{E}\\left[ | \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2 \\right] = \\mathrm{E} \\left[ \\left( \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i \\right) \\left( \\mathbf{h}_i^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_k \\right) \\right] $ This can be rewritten as: $ \\mathrm{E} \\left[ | \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2 \\right] = \\mathrm{E} \\left[ \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i \\mathbf{h}_i^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_k \\right] $\n",
    "\n",
    "### Trace Operator\n",
    "\n",
    "Using the properties of the trace operator: $ \\mathrm{E} \\left[ \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i \\mathbf{h}_i^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_k \\right] = \\mathrm{E} \\left[ \\mathrm{tr} \\left( \\mathbf{h}_i \\mathbf{h}_i^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\right) \\right] $,  by the linearity of the trace and expectation, we get: $ \\mathrm{E} \\left[ \\mathrm{tr} \\left( \\mathbf{h}_i \\mathbf{h}_i^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\right) \\right] = \\mathrm{E} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i \\mathbf{h}_i^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\right) \\right] $\n",
    "\n",
    "### Expectation and Simplification\n",
    "\n",
    "Since $\\mathbf{h}_i$ and $\\mathbf{h}_k$ are independent zero-mean complex Gaussian vectors: $ \\mathbf{h}_i \\sim \\mathcal{CN}(0, \\frac{\\alpha_i}{N} \\mathbf{I}_N) $ and $ \\mathbf{h}_k \\sim \\mathcal{CN}(0, \\frac{\\alpha_k}{N} \\mathbf{I}_N) $, We have: $ \\mathrm{E} \\left[ \\mathbf{h}_i \\mathbf{h}_i^H \\right] = \\frac{\\alpha_i}{N} \\mathbf{I}_N $ and $ \\mathrm{E} \\left[ \\mathbf{h}_k \\mathbf{h}_k^H \\right] = \\frac{\\alpha_k}{N} \\mathbf{I}_N $\n",
    "\n",
    "### Putting It All Together\n",
    "\n",
    "Now, consider: $ \\mathrm{E} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i \\mathbf{h}_i^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_k \\mathbf{h}_k^H \\right) \\right] $. Since $\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp$ is orthogonal and symmetric, we get: $ \\mathrm{E} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\frac{\\alpha_i}{N} \\mathbf{I}_N \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\frac{\\alpha_k}{N} \\mathbf{I}_N \\right) \\right] $. This simplifies to: $ \\frac{\\alpha_i \\alpha_k}{N^2} \\mathrm{E} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\right) \\right] $\n",
    "\n",
    "### Trace of the Projection Matrix\n",
    "\n",
    "Using the property of the projection matrix $\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp$: $ \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp = \\mathbf{I}_N - \\mathbf{P}_{\\mathbf{H}_{I_i}} $. We know that $\\mathbf{P}_{\\mathbf{H}_{I_i}}$ has a trace equal to its rank, which is $K_i$. Thus, the trace of $\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp$ is: $ \\mathrm{tr}(\\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp) = N - K_i $. So, we have: $ \\mathrm{E} \\left[ \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\right) \\right] = N - K_i $. Thus, the expected interference term simplifies to: $ \\frac{\\alpha_i \\alpha_k}{N^2} \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\right) = \\frac{\\alpha_i \\alpha_k}{N^2} (N - K_i) = \\frac{\\alpha_i \\alpha_k}{N} \\left(1 - \\frac{K_i}{N}\\right) $\n",
    "\n",
    "#### $ {\\color{salmon} \\framebox[1][10]{ Solution: } }$\n",
    "\n",
    "Therefore, we have shown that: $\\boxed{  \\mathrm{E} | \\mathbf{h}_k^H \\, \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2 = \\frac{\\alpha_i \\alpha_k}{N^2} \\mathrm{tr} \\left( \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\right) = \\frac{\\alpha_i \\alpha_k}{N^2} (N - K_i) = \\frac{\\alpha_i \\alpha_k}{N} \\left(1 - \\frac{K_i}{N}\\right) }$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394dc444-26d6-435b-8326-856b08fb045a",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x70;)** ___Finally show that we can write___\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{SINR}_k^{ro} = \\frac{ p_k ( 1 - \\frac{K_k}{N} ) }{ \\frac{1}{N} \\displaystyle\\sum_{i=1,k \\notin  I_i}^K p_i + \\frac{\\sigma_k^2}{\\alpha_k}} .\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d63d1-d907-4a3a-a7b9-e4ba408255b1",
   "metadata": {},
   "source": [
    "To show that $ \\text{SINR}_k^{ro} = \\frac{ p_k \\left( 1 - \\frac{K_k}{N} \\right) }{ \\frac{1}{N} \\sum_{i=1, k \\notin I_i}^K p_i + \\frac{\\sigma_k^2}{\\alpha_k} }, $ we will use the results from the previous steps to derive the signal and interference powers.\n",
    "\n",
    "### Signal Power\n",
    "\n",
    "From part **&#x1F516;** **(&#x6d;)**, we have: $ \\frac{P_{S,k}}{p_k} = \\sigma_k \\left( 1 - \\frac{K_k}{N} \\right). $ Thus, the signal power $P_{S,k}$ is: $ P_{S,k} = p_k \\cdot \\sigma_k \\left( 1 - \\frac{K_k}{N} \\right) $\n",
    "\n",
    "### Interference Power\n",
    "\n",
    "From part **&#x1F516;** **(&#x6e;)**, the expected interference power $\\mathrm{E} \\left[ | \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2 \\right]$ for $k \\notin I_i$ is: $ \\mathrm{E} \\left[ | \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2 \\right] = \\frac{\\alpha_k \\alpha_i}{N} \\left(1 - \\frac{K_i}{N}\\right). $ Using this, we can calculate the interference power $P_{I,k}$ as follows: $ P_{I,k} = \\sum_{i=1, i \\neq k}^K p_i \\mathrm{E} \\left[ | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} |^2 \\right] $\n",
    "\n",
    "From part **&#x1F516;** **(&#x6c;)**, we know that: $ \\mathrm{E} \\left[ | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} |^2 \\right] = \\frac{\\mathrm{E} \\left[ | \\mathbf{h}_k^H \\mathbf{P}_{\\mathbf{H}_{I_i}}^\\perp \\mathbf{h}_i |^2 \\right]}{\\frac{P_{S,i}}{p_i}}. $ Substituting $ \\frac{P_{S,i}}{p_i} = \\alpha_i \\left( 1 - \\frac{K_i}{N} \\right) $: $ \\mathrm{E} \\left[ | \\mathbf{h}_k^H \\mathbf{g}_i^{ro} |^2 \\right] = \\frac{\\frac{\\alpha_k \\alpha_i}{N} \\left(1 - \\frac{K_i}{N}\\right)}{\\alpha_i \\left( 1 - \\frac{K_i}{N} \\right)} = \\frac{\\alpha_k}{N}. $ Thus: $ P_{I,k} = \\sum_{i=1, i \\neq k}^K p_i \\cdot \\frac{\\alpha_k}{N}. $ Simplifying: $ P_{I,k} = \\frac{\\alpha_k}{N} \\sum_{i=1, i \\neq k}^K p_i $\n",
    "\n",
    "### Noise Power\n",
    "\n",
    "The noise power is given by: $ \\sigma_k^2 $\n",
    "\n",
    "#### $\\color{salmon} \\text{SINR Calculation}$\n",
    "\n",
    "Now, we can write the SINR expression: $ \\text{SINR}_k^{ro} = \\frac{P_{S,k}}{P_{I,k} + \\sigma_k^2} .$\n",
    "- Substitute the values of $P_{S,k}$, $P_{I,k}$, and $\\sigma_k^2$: $ \\text{SINR}_k^{ro} = \\frac{p_k \\cdot \\sigma_k \\left( 1 - \\frac{K_k}{N} \\right)}{\\frac{\\alpha_k}{N} \\displaystyle\\sum_{i=1, i \\neq k}^K p_i + \\sigma_k^2}. $\n",
    "- Factor out $\\alpha_k$ from the denominator: $ \\text{SINR}_k^{ro} = \\frac{p_k \\cdot \\sigma_k \\left( 1 - \\frac{K_k}{N} \\right)}{\\alpha_k \\left( \\frac{1}{N} \\displaystyle\\sum_{i=1, i \\neq k}^K p_i + \\frac{\\sigma_k^2}{\\alpha_k} \\right)} .$\n",
    "- Simplify the fraction: $ \\text{SINR}_k^{ro} = \\frac{p_k \\left( 1 - \\frac{K_k}{N} \\right)}{\\frac{1}{N} \\displaystyle\\sum_{i=1, i \\neq k}^K p_i + \\frac{\\sigma_k^2}{\\alpha_k}} .$\n",
    "\n",
    "Since $ \\displaystyle\\sum_{i=1, i \\neq k}^K p_i $ is approximately equal to $ \\displaystyle\\sum_{i=1, k \\notin I_i}^K p_i .$ In the context of interference: \n",
    "\n",
    "$$\n",
    "\\boxed{ \n",
    "\\text{SINR}_k^{ro} = \\frac{ p_k \\left( 1 - \\frac{K_k}{N} \\right) }{ \\frac{1}{N} \\displaystyle\\sum_{i=1, k \\notin I_i}^K p_i + \\frac{\\sigma_k^2}{\\alpha_k} } \n",
    "}\n",
    "$$\n",
    "\n",
    "This shows how the SINR decreases with increasing zero-forcing order $K_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639f46a-ec37-4187-8f16-cbe945883547",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x71;)** ___Show that for the full order ZF, we get from this___\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{SINR}_k^{ZF} = \\frac{ \\alpha_k \\, p_k } { \\sigma_k^2 }  ( 1 - \\frac{K - 1}{N} )  .\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f149445-3cda-471b-865a-86ed9c0db287",
   "metadata": {},
   "source": [
    "To show that for the full-order zero-forcing (ZF), the SINR expression becomes: $ \\text{SINR}_k^{ZF} = \\frac{\\alpha_k \\, p_k}{\\sigma_k^2} \\left( 1 - \\frac{K - 1}{N} \\right), $ we will start from the derived expression for $\\text{SINR}_k^{ro}$ and adapt it for the case where full-order ZF is used.\n",
    "\n",
    "### Full-Order ZF\n",
    "\n",
    "In the full-order ZF scenario, the beamformer zero-forces the interference to all other users except the desired user. Thus, the ZF order $K_k$ for user $k$ will be $K - 1$, as it needs to zero-force to $K - 1$ other users.\n",
    "\n",
    "### SINR Expression for Full-Order ZF\n",
    "\n",
    "We start with the previously derived SINR expression for reduced-order ZF: $ \\text{SINR}_k^{ro} = \\frac{p_k \\left( 1 - \\frac{K_k}{N} \\right)}{\\frac{1}{N} \\displaystyle\\sum_{i=1, k \\notin I_i}^K p_i + \\frac{\\sigma_k^2}{\\alpha_k}} $\n",
    "\n",
    "For full-order ZF, where $K_k = K - 1$:\n",
    "\n",
    "1. **Signal Power Term:**\n",
    "\n",
    "   The term for the signal power becomes: $ 1 - \\frac{K_k}{N} = 1 - \\frac{K - 1}{N} $\n",
    "\n",
    "2. **Interference Power Term:**\n",
    "\n",
    "   In full-order ZF, the beamformer zero-forces to all other users, so ideally the interference power term should be zero because $\\mathbf{g}_i^{ZF}$ is orthogonal to $\\mathbf{h}_k$ for $i \\neq k$. This simplifies the denominator to: $ \\text{Interference Power} = 0 $\n",
    "\n",
    "3. **Noise Power Term:**\n",
    "\n",
    "   The noise power term remains the same: $ \\text{Noise Power} = \\sigma_k^2 $\n",
    "\n",
    "### Simplified SINR Expression\n",
    "\n",
    "With these simplifications, the SINR expression becomes: $ \\text{SINR}_k^{ZF} = \\frac{p_k \\left( 1 - \\frac{K - 1}{N} \\right)}{\\frac{\\sigma_k^2}{\\alpha_k}} $\n",
    "\n",
    "#### $ {\\color{salmon} \\framebox[1][10]{ Solution: } }$\n",
    "\n",
    "Simplify the fraction by multiplying the numerator and the denominator by $\\alpha_k$: $ \\text{SINR}_k^{ZF} = \\frac{\\alpha_k \\, p_k \\left( 1 - \\frac{K - 1}{N} \\right)}{\\sigma_k^2} $\n",
    "\n",
    "This shows that for full-order ZF, the SINR is: $\\boxed{ \\text{SINR}_k^{ZF} = \\frac{\\alpha_k \\, p_k}{\\sigma_k^2} \\left( 1 - \\frac{K - 1}{N} \\right) }.$ This completes the derivation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7282f1a2-1bac-447b-ae30-f3b01d3107e5",
   "metadata": {},
   "source": [
    "#### **&#x1F516;** **(&#x72;)** ___On the other hand we get for a Matched Filter, which is a $\\text{zero}^{\\text{th}}$ order ZF $(K_k = 0)$,___\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{SINR}_k^{MF} = \\frac{ p_k } { ( \\frac{P - p_k}{N} + \\frac{\\sigma_k^2}{\\sigma_k} ) }    \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where P is the sum power of the BS. What does this give in the case of uniform powers $p_k =P/K$?\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f1b13-18d9-41a5-87ed-d3db5c66cb29",
   "metadata": {},
   "source": [
    "To show the SINR for a Matched Filter (MF), which is the zero-order ZF ($K_k = 0$), and to derive the expression for uniform powers $p_k = \\frac{P}{K}$, we start with the given expression for $\\text{SINR}_k^{MF}$: $ \\text{SINR}_k^{MF} = \\frac{p_k}{\\left( \\frac{P - p_k}{N} + \\frac{\\sigma_k^2}{\\alpha_k} \\right)}. $ Here, $P$ is the total transmit power of the base station, and $p_k$ is the power allocated to user $k$.\n",
    "\n",
    "### Case of Uniform Powers\n",
    "\n",
    "For uniform power allocation, we have: $ p_k = \\frac{P}{K}. $ Substituting this into the SINR expression: $ \\text{SINR}_k^{MF} = \\frac{\\frac{P}{K}}{\\left( \\frac{P - \\frac{P}{K}}{N} + \\frac{\\sigma_k^2}{\\alpha_k} \\right)} $\n",
    "\n",
    "### Simplification\n",
    "\n",
    "1. **Simplify the Interference Term:**\n",
    "\n",
    "   $ P - \\frac{P}{K} = P \\left( 1 - \\frac{1}{K} \\right) = \\frac{P(K-1)}{K}. $ Substituting this back into the denominator: $ \\text{SINR}_k^{MF} = \\frac{\\frac{P}{K}}{\\left( \\frac{\\frac{P(K-1)}{K}}{N} + \\frac{\\sigma_k^2}{\\alpha_k} \\right)} $\n",
    "\n",
    "2. **Simplify the Denominator:**\n",
    "\n",
    "   $ \\frac{\\frac{P(K-1)}{K}}{N} = \\frac{P(K-1)}{KN}. $ So the denominator becomes: $ \\frac{P(K-1)}{KN} + \\frac{\\sigma_k^2}{\\alpha_k} $\n",
    "\n",
    "3. **Final Expression:**\n",
    "\n",
    "   - Substituting this back into the SINR expression: $ \\text{SINR}_k^{MF} = \\frac{\\frac{P}{K}}{\\frac{P(K-1)}{KN} + \\frac{\\sigma_k^2}{\\alpha_k}}. $\n",
    "   - Simplify the fraction by multiplying the numerator and denominator by $K$: $ \\text{SINR}_k^{MF} = \\frac{P}{\\frac{P(K-1)}{N} + K \\frac{\\sigma_k^2}{\\alpha_k}}. $\n",
    "   - Divide both the numerator and the denominator by $P$: $ \\text{SINR}_k^{MF} = \\frac{1}{\\frac{K-1}{N} + \\frac{K \\sigma_k^2}{P \\alpha_k}} $\n",
    "\n",
    "#### $ {\\color{salmon} \\framebox[1][10]{ Solution: } }$\n",
    "\n",
    "For uniform power allocation $p_k = \\frac{P}{K}$, the SINR for a Matched Filter (MF) is given by: $\\boxed{ \\text{SINR}_k^{MF} = \\frac{1}{\\frac{K-1}{N} + \\frac{K \\sigma_k^2}{P \\alpha_k}} }$\n",
    "\n",
    "This expression indicates how the SINR for the matched filter decreases with the number of users $K$, the number of antennas $N$, the noise power $\\sigma_k^2$, and the total power $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d579189-2292-4a25-b933-431d90060090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
