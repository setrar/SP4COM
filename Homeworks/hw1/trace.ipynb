{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b27df2d-f67a-49c8-90ce-cbbe7d360b57",
   "metadata": {},
   "source": [
    "# How the trace of $tr\\{R\\}$ is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ae655-f67b-46c9-b375-62c4409ab9a0",
   "metadata": {},
   "source": [
    "In the context of adaptive filtering and signal processing, the trace of the autocorrelation matrix $ R $ of the input signal plays a significant role in analyzing and determining the behavior of adaptive algorithms such as the Least Mean Squares (LMS) algorithm. The autocorrelation matrix $ R $ is a crucial element that characterizes the statistical properties of the input signal. Understanding how the trace of this matrix is used can help in both theoretical analyses and practical implementations of these algorithms.\n",
    "\n",
    "### Definition and Importance of the Trace of R\n",
    "\n",
    "The autocorrelation matrix $R_{\\mathbf{X}\\mathbf{X}} $ is defined for a signal vector $ \\mathbf{x} $ (which could represent, for instance, samples of a signal at different times) as:\n",
    "$ R_{\\mathbf{X}\\mathbf{X}} = E[\\mathbf{x} \\mathbf{x}^T] $\n",
    "where $ E $ denotes the expectation operator, and $ \\mathbf{x}^T $ is the transpose of $ \\mathbf{x} $.\n",
    "\n",
    "The trace of the matrix $ R $, denoted as $ \\text{Tr}(R) $, is the sum of its diagonal elements. Since the diagonal elements of $ R $ are the autocorrelations at zero lag (i.e., the variances of the individual components of $ \\mathbf{x} $), the trace represents the total power or energy of the signal over all its components.\n",
    "\n",
    "### Role of Trace of R in Adaptive Filtering\n",
    "\n",
    "1. **Stability and Convergence**: In adaptive filters like the LMS algorithm, the step size $ \\mu $ is a critical parameter that affects the stability and convergence rate of the algorithm. The stability condition often requires that:\n",
    "   $ 0 < \\mu < \\frac{2}{\\lambda_{\\text{max}}} $\n",
    "   where $ \\lambda_{\\text{max}} $ is the maximum eigenvalue of $ R $. However, a more practical and easy-to-calculate limit uses the trace of $ R $, since the trace is also the sum of all eigenvalues of $ R $, given by:\n",
    "   $ 0 < \\mu < \\frac{2}{\\text{Tr}(R)} $\n",
    "   This ensures that the step size is small enough to guarantee stability but not so small that convergence becomes impractically slow.\n",
    "\n",
    "2. **Misadjustment and Excess MSE**: The trace of $ R $ also appears in expressions estimating the misadjustment or the excess mean square error (MSE) due to the adaptation of the filter. A simplified formula to estimate the steady-state excess MSE involves the trace:\n",
    "   $ \\text{MSE}_{\\text{excess}} \\approx \\mu \\text{Tr}(R) \\sigma^2_n $\n",
    "   where $ \\sigma^2_n $ is the variance of the noise in the desired signal. This expression indicates that as $ \\text{Tr}(R) $ increases (which can happen with either higher power signals or more correlated signals), the potential excess MSE due to adaptation also increases, unless the step size $ \\mu $ is adjusted accordingly.\n",
    "\n",
    "3. **Optimization of Algorithm Parameters**: By understanding the relationship between the trace of $ R $, the step size $ \\mu $, and the adaptive filter's performance, designers can optimize $ \\mu $ to achieve a desired trade-off between the speed of adaptation and the steady-state performance of the filter.\n",
    "\n",
    "In summary, the trace of the autocorrelation matrix $ R $ is used primarily to guide the selection of the step size $ \\mu $ in adaptive filtering algorithms to ensure stability and to optimize performance. It offers a balance between mathematical rigor and computational simplicity, making it a valuable tool in the design and analysis of adaptive signal processing systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd3bd5-fd62-4610-be83-d1b14a7ca34d",
   "metadata": {},
   "source": [
    "To demonstrate the use of the trace of the autocorrelation matrix \\( R \\) in Julia, I will create a simple example where we compute the autocorrelation matrix of a random signal, find its trace, and then use it to determine a stable step size \\( \\mu \\) for the LMS algorithm. The script will include generating a random signal, computing \\( R \\), finding its trace, and applying these in a basic LMS setup to adjust the filter coefficients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17292309-7660-463d-aa10-bb1fb15b91e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra  # For matrix operations\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467b46ef-dd07-491d-9234-349eddb7d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LaTeXStrings\n",
    "using FFTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4354421-b5eb-4cc9-9493-f11ae7f2c0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean (generic function with 6 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "𝖤 = mean # E denotes the expectation operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1cf15cc-6cdc-4504-86bb-4f2b1569f208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "norm (generic function with 12 methods)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"_support/operations.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "151b13a2-dce9-4c7c-b89f-f65c5cb3d7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lms (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"lms.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea5df01-4ed2-4f01-9634-4c63a3116acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of R: 1021.4918513928553\n",
      "Stable step size μ: 0.0009789603300667058\n",
      "Filter coefficients 𝗳: [-0.0028502471363227567, 0.6197962168169512, -0.004740374873734474]\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "𝑓ₛ = 50 # N length\n",
    "x = randn(1000) # Generate a signal\n",
    "\n",
    "# Compute autocorrelation matrix R\n",
    " # 𝑅ₓₓ = autocorrelation_matrix(x[1:N])\n",
    "N = length(x)\n",
    "𝑅ₓₓ = [i != j ? \n",
    "        𝖤( x[ 1 : N - |(i-j) ] .* x[ |(i-j) + 1 : N] ) : # |() is the abs operator \n",
    "        𝖤(x .* x) # 𝖤 is the mean operator - Expected Value\n",
    "            for i in 1:N, j in 1:N\n",
    "        ]\n",
    "\n",
    "# Compute a stable step size μ\n",
    "μ = 1.0 / tr(𝑅ₓₓ)  # A simple rule to ensure stability\n",
    "\n",
    "# Generate a desired signal (for example purposes, let's just use a delayed version of the input)\n",
    "y = [0; x[1:end-1]]  # Simple delay\n",
    "\n",
    "# Simulate LMS\n",
    "𝗳, ϵ = lms(InputLMS(x, y, μ, 𝑓ₛ))\n",
    "\n",
    "# Output the results\n",
    "println(\"Trace of R: \", tr(𝑅ₓₓ))\n",
    "println(\"Stable step size μ: \", μ)\n",
    "println(\"Filter coefficients 𝗳: \", 𝗳[1:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e6619-c43a-416f-acc2-6bb6fa906355",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "1. **Signal Generation**: The `generate_signal` function creates a random signal, which is used both as the input signal and, with a simple delay, as the desired signal for the LMS algorithm.\n",
    "\n",
    "2. **Autocorrelation Matrix Calculation**: The `autocorrelation_matrix` function computes the autocorrelation matrix \\( R \\) for a given segment of the signal. Note that for simplicity and to avoid complexities, this example computes \\( R \\) in a straightforward but not computationally efficient manner.\n",
    "\n",
    "3. **Trace Calculation**: The trace of \\( R \\) is calculated using Julia's `tr` function from the `LinearAlgebra` package.\n",
    "\n",
    "4. **Stability and LMS Simulation**: The stable step size \\( \\mu \\) is estimated as the reciprocal of the trace of \\( R \\). This step size is then used in the `simulate_lms` function, which implements a basic version of the LMS algorithm to adapt filter coefficients based on the input and desired signals.\n",
    "\n",
    "5. **Outputs**: The script prints out the trace of \\( R \\), the chosen step size \\( \\mu \\), and the adapted filter coefficients.\n",
    "\n",
    "This example should help in understanding how the trace of the autocorrelation matrix \\( R \\) is used to guide the setting of parameters in adaptive filtering scenarios, providing a basis for further exploration and practical implementations in signal processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc68ee7-fec4-4257-b222-912efd7d8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e53a929-ac54-4443-8ae7-9acd580d1052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the autocorrelation matrix\n",
    "hm = heatmap(𝑅ₓₓ, color=:blues, aspect_ratio=:equal,\n",
    "        title=\"Autocorrelation Matrix\",\n",
    "        xlabel=\"Lag Index j\",\n",
    "        ylabel=\"Lag Index i\",\n",
    "        xticks=(1:10:100, string.(1:10:100)),\n",
    "        yticks=(1:10:100, string.(1:10:100)),\n",
    "        clims=(minimum(𝑅ₓₓ), maximum(𝑅ₓₓ)))\n",
    "savefig(hm,\"images/heatmap_RXX.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57774914-a86b-49d7-967f-788927e6e630",
   "metadata": {},
   "source": [
    "<img src=images/heatmap_RXX.png width='' height='' > </img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22db9b95-75c4-4ed3-91c3-dbcee9f23221",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7525ae2a-6a9d-476a-93a9-e4f46bf5bbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "norm (generic function with 15 methods)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"_support/operations.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91beea7e-b5b6-4612-a5c9-e46a10de8eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample covariance matrix R_XX is:\n",
      "[1.0281190371798719 -0.002691592680764655 -0.030073273296109232; -0.002691592680764655 0.9858257968839846 -0.019164689528511872; -0.030073273296109232 -0.019164689528511872 0.975748939534086]\n"
     ]
    }
   ],
   "source": [
    "# Set the dimensions and sample size\n",
    "n = 3  # Dimension of each vector\n",
    "m = 1000  # Number of samples\n",
    "\n",
    "# Generate a matrix X of size m x n with normally distributed entries\n",
    "X = randn(m, n)\n",
    "\n",
    "# Compute the sample matrix R_XX as an approximation of E[x x^T]\n",
    "Rₓₓ = ((X)ᵀ * X) / m\n",
    "\n",
    "# Display the result\n",
    "println(\"The sample covariance matrix R_XX is:\")\n",
    "println(Rₓₓ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4f70f0a-bff4-478e-ae1a-8c635a697c77",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching length(::Transposer)\n\n\u001b[0mClosest candidates are:\n\u001b[0m  length(\u001b[91m::LibGit2.GitStatus\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mLibGit2\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.10.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.10/LibGit2/src/\u001b[39m\u001b[90m\u001b[4mstatus.jl:21\u001b[24m\u001b[39m\n\u001b[0m  length(\u001b[91m::DataStructures.EnumerateAll\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDataStructures\u001b[39m \u001b[90m~/.julia/packages/DataStructures/95DJa/src/\u001b[39m\u001b[90m\u001b[4mmulti_dict.jl:96\u001b[24m\u001b[39m\n\u001b[0m  length(\u001b[91m::DataStructures.DiBitVector\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDataStructures\u001b[39m \u001b[90m~/.julia/packages/DataStructures/95DJa/src/\u001b[39m\u001b[90m\u001b[4mdibit_vector.jl:40\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching length(::Transposer)\n\n\u001b[0mClosest candidates are:\n\u001b[0m  length(\u001b[91m::LibGit2.GitStatus\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mLibGit2\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.10.2+0.aarch64.apple.darwin14/share/julia/stdlib/v1.10/LibGit2/src/\u001b[39m\u001b[90m\u001b[4mstatus.jl:21\u001b[24m\u001b[39m\n\u001b[0m  length(\u001b[91m::DataStructures.EnumerateAll\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDataStructures\u001b[39m \u001b[90m~/.julia/packages/DataStructures/95DJa/src/\u001b[39m\u001b[90m\u001b[4mmulti_dict.jl:96\u001b[24m\u001b[39m\n\u001b[0m  length(\u001b[91m::DataStructures.DiBitVector\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mDataStructures\u001b[39m \u001b[90m~/.julia/packages/DataStructures/95DJa/src/\u001b[39m\u001b[90m\u001b[4mdibit_vector.jl:40\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] _similar_shape(itr::Transposer, ::Base.HasLength)",
      "   @ Base ./array.jl:710",
      " [2] _collect(cont::UnitRange{Int64}, itr::Transposer, ::Base.HasEltype, isz::Base.HasLength)",
      "   @ Base ./array.jl:765",
      " [3] collect(itr::Transposer)",
      "   @ Base ./array.jl:759",
      " [4] broadcastable(x::Transposer)",
      "   @ Base.Broadcast ./broadcast.jl:743",
      " [5] broadcasted(::typeof(*), ::Vector{Int64}, ::Transposer)",
      "   @ Base.Broadcast ./broadcast.jl:1345",
      " [6] top-level scope",
      "   @ In[12]:6"
     ]
    }
   ],
   "source": [
    "# Mean vector and standard deviations\n",
    "μ = [0, 1, 2]  # Means for each of the n dimensions\n",
    "σ = [1, 2, 3]  # Standard deviations for each of the n dimensions\n",
    "\n",
    "# Generate a matrix X of size m x n with normally distributed entries according to μ and σ\n",
    "Y = @. randn(m, n) * (σ)ᵀ + (μ)ᵀ\n",
    "\n",
    "# Compute the sample covariance matrix\n",
    "Rᵧᵧ = ((Y)ᵀ * Y - m * (μ)ᵀ * μ) / (m - 1)  # Unbiased estimator\n",
    "\n",
    "# Display the result\n",
    "println(\"The sample covariance matrix R_XX is:\")\n",
    "println(Rᵧᵧ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11d96929-6ac9-49d8-b05a-4c8231721619",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching -(::Matrix{Float64}, ::Int64)\nFor element-wise subtraction, use broadcasting with dot syntax: array .- scalar\n\n\u001b[0mClosest candidates are:\n\u001b[0m  -(\u001b[91m::BigInt\u001b[39m, ::Union{Int16, Int32, Int64, Int8})\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mgmp.jl:557\u001b[24m\u001b[39m\n\u001b[0m  -(\u001b[91m::BigFloat\u001b[39m, ::Union{Int16, Int32, Int64, Int8})\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmpfr.jl:494\u001b[24m\u001b[39m\n\u001b[0m  -(\u001b[91m::Missing\u001b[39m, ::Number)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:123\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching -(::Matrix{Float64}, ::Int64)\nFor element-wise subtraction, use broadcasting with dot syntax: array .- scalar\n\n\u001b[0mClosest candidates are:\n\u001b[0m  -(\u001b[91m::BigInt\u001b[39m, ::Union{Int16, Int32, Int64, Int8})\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mgmp.jl:557\u001b[24m\u001b[39m\n\u001b[0m  -(\u001b[91m::BigFloat\u001b[39m, ::Union{Int16, Int32, Int64, Int8})\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmpfr.jl:494\u001b[24m\u001b[39m\n\u001b[0m  -(\u001b[91m::Missing\u001b[39m, ::Number)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmissing.jl:123\u001b[24m\u001b[39m\n\u001b[0m  ...\n",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[13]:15"
     ]
    }
   ],
   "source": [
    "using Random, LinearAlgebra\n",
    "\n",
    "# Parameters\n",
    "n = 3  # Dimension of each vector\n",
    "m = 1000  # Number of samples\n",
    "\n",
    "# Mean vector and standard deviations\n",
    "μ = [0, 1, 2]  # Means for each of the n dimensions\n",
    "σ = [1, 2, 3]  # Standard deviations for each of the n dimensions\n",
    "\n",
    "# Generate a matrix X of size m x n with normally distributed entries according to μ and σ\n",
    "X = randn(m, n) .* σ' .+ μ'\n",
    "\n",
    "# Compute the sample covariance matrix\n",
    "R_XX = (X' * X - m * μ' * μ) / (m - 1)  # Unbiased estimator\n",
    "\n",
    "# Display the result\n",
    "println(\"The sample covariance matrix R_XX is:\")\n",
    "println(R_XX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a0e5f-2007-45f4-8528-fd38e1e44bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
